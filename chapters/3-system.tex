\chapter{系統架構與實作}
\label{chapter:system}


\section{實驗平台: free5GC 系統介紹}
\label{sec:free5gc_intro}

%同時介紹 free5GC control plan 採用 Golang 開發，並且介紹 Golang

\section{系統層 ABI: OpenNetVM 系統介紹}
\label{sec:opennetvm_intro}

\section{系統架構總覽}
\label{sec:arch_intro}

\section{SMF 移植細節}
\label{sec:smf_porting}

% 5G 所有 interface

雖然 5G 使用 SBI 架構整合了大部分的控制端界面，但還是保留了 NGAP 跟 PFCP 於 N2 及 N4 界面 (見圖~\ref{fig:5g_system_architecture})，其中 N2 是介於基地臺 (RAN) 與 AMF 之間的通訊，透過 NGAP 協定，類似於 4G 時代的 S1AP 協定，而 N4 則是 SMF 與 UPF 間的界面，沿用 4G R10 之後 CU 分離概念所使用的 PFCP 協定。在這主要的三個界面中，SBI 是基於 HTTP2，傳輸層 (L4, transport layer) 是使用的是 TCP，NGAP 的傳輸層使用 SCTP，而 PFCP 的傳輸層使用的是 UDP。

\begin{figure}[ht]
  \centering
  \subcaptionbox[b]{
    5G 系統架構，控制端用 SBI 表示
    \label{fig:5g_system_architecture_sbi}
  }{
    \includegraphics[height=!,width=0.45\linewidth,keepaspectratio=true]
                    {figures/23_501_4-2-3-1_sys_arch_sbi}
  }
  \subcaptionbox[b]{
    5G 系統架構，控制端用參考點表示
    \label{fig:5g_system_architecture_interface}
  }{
    \includegraphics[height=!,width=0.45\linewidth,keepaspectratio=true]
                    {figures/23_501_4-2-3-2_sys_arch_ref}
  }
  % [] 放的是顯示在 list of figure 的文字
  % {} 放的是顯示在圖下方的文字
  \caption[5G 系統架構]{{\footnotesize 5G 系統架構~\cite{3gpp.23.501}}}
  \label{fig:5g_system_architecture}
\end{figure}

% SMF 所使用的 interface，並且決定只作 PFCP (N4 interface)
% 可以的話舉證 Session mgmt 重要於 mobility 與 regisration/deregistration

為了加速控制端的控制訊號 (control signal) 可以更快的新增、修改、刪除用戶端的會話 (session)，我們希望可以透過加速 AMF、SMF、與 UPF 這三個於 PDU Session 流程中最重要的三個 Network Function 之間的通訊速度，降低其三者間的通訊延遲 (latency)，得以在 5G 核心網路進行大量會話的新增、修改、與刪除中，得到最好的效能。

在 AMF、SMF、與 UPF 中，SMF 是負責 Session 管理的 Network Function，即是 Session 管理最重要的部件，因此我們希望優先著重於其控制信號的效能最佳化。而在 SMF 的界面中，又以 N4 界面用以對 UPF 下達 Session 管理的界面最為重要，因此我們決定於 N4 界面上，透過 OpenNetVM 物理層傳輸效能的優勢取代傳統 Berkeley Socket，藉以提高 N4 介面的傳輸效能，降低控制訊號的延遲。

% 移植理由

原生的 free5GC 控制端是建構在 Linux 的 Berkeley Socket 上，先將 L4 層以上的負載內容 (payload) 封裝後，再透過呼叫 Berkeley Socket API，來達成封包傳送的功能。但由於 Berkeley Socket 屬於 user space library API，並且在傳送過程中，至少會經過兩次記憶體複製 (memory copy) (會先複製到 per process 的 kernel space memory，再複製到 network device 的 newtowrk queue)，相對於後來出現的技術諸如 DPDK 或 XDP，實屬效能不彰。另外，即便是將 Network Function 部屬於同一機器上，由於 Berkeley Socket 屬於 RPC，傳送路徑必定會經過 Network Device，無法自動判定為 IPC 而使用更高效率的傳輸方式。基於以上理由，我們希望透過 OpenNetVM 的性質，同時可以於 RPC 下使用 DPDK 功能，與 IPC 使用 shared memory 功能，實現完全零記憶體複製 (zero copy)，以及可於同一主機下使用 IPC 來達到更佳的傳輸效率。

% 開發選擇
在 SMF 移植的設計上，由於 OpenNetVM 所提供的是 C 語言的 API，而 free5GC 的 SMF 所使用的是 Golang 語言開發，因此需要考慮到如何跨語言移植。在設計之初有考慮是否需要透過 IPC 溝通，另外啟動一個 relay 將 SMF 的訊息 (message) 先透過 IPC 傳送到 relay process，再由 relay process 呼叫 OpenNetVM API。但由於發現 Golang 本身有提供 CGO 的功能，透過指定語法可以直接呼叫 C 語言 API，因此我們決定以此方法，減少 IPC 溝通的效能損耗。CGO 提供 C 呼叫 Go 語言函式或是 Go 呼叫 C 語言函式，若是以 C 呼叫 Golang，需要先將 Go 函式庫編譯成 share object library (.so 或 .dll 檔)，之後再讓 C 語言透過 share object 的方式呼叫，呼叫過程中由於已經編譯成 object file 並使用 dynimic linking 的方式，是由程式跑起來後 loader 來處理，因此對 caller (C 語言程式) 幾乎沒有任何限制。反之如果是 Golang 呼叫 C 語言函式庫，則會有較多限制，例如 callee 部可以有信號 (signal) 呼叫 (基於 golang 本身訊號覆蓋(signal mask)機制)、部分型別需要做強型別轉換、需要透過 cgo flag 讓編譯器或連結器得到相對 library 絕對位置等等。

儘管透過 C program 呼叫 Golang shared library 在實踐成本上遠低於使用 Golang 呼叫 C library，但我們希望在程式設計上可以提供更高的擴充性 (scalibility) 與更加一般化 (generalize)，且若可以設計成 函式庫 (library) 形式，會更加利於使用者使用且可以不僅限此專案使用，因此我們希望嘗試以可以直接使用之 Golang 函式庫方向開發。

由於從 OpenNetVM API 上獲取的封包是直接傳回封包所在記憶體位置的指標，而封包爲連結層 (link layer) 之上的內容，因此我們決定開發成類似 Goalng 原生之 net 函式庫，透過 Golang 所提供的 interface 性質，直接取代掉 PFCP 底層之 \lstinline[language=Go]{net.UdpConn} interface，我們命名之 \lstinline[language=Go]{onvmNet.ONVMConn}~\cite{github.onvmNet} interface。

在設計此函式庫時有部分條件需要考慮，首先，由於 Golang 在透過 CGO 呼叫 C 函式時，有不可呼叫內部有訊號註冊 (signal handling) 的函式，其原因爲 golang 本身有對訊號作內部處理，因此如果透過外部語言另外註冊訊號，會影響 Golang 程序底層訊號處理，但由於 OpenNetVM 在初始化階段需要透過 OpenNetVM 的 API 對系統作訊號註冊，因此會出現問題。而我們參考了網路上的解決方法，將訊號註冊放置 Golang 的 \lstinline[language=Go]{init} 函式，\lstinline[language=Go]{init} 函式是 Golang 設計給予在 main 函式執行起來前，就預先執行的函式，類似 C 語言的 \lstinline[language=C]{__attribute__ ((constructor))}。

然而，使用 \lstinline[language=Go]{init} 函式會遇到初始化參數無法透過程式執行過程中傳遞，因此我們採用 OpenNetVM 提供的 NF config 設計，透過 config 檔預先傳入 OpenNetVM 平臺之必要參數，諸如 DPDK 參數、Service ID、Instence ID 等。

又因為 OpenNetVM 是使用 Service ID 來決定封包目的地應該傳送至那一個 Network Function，而非使用傳統的 IP 來做 routing，因此我們也對應設計了 ipid.yaml 的檔案預先定義 IP 與 Service ID 的對應關係。透過這樣的設計，函式呼叫者 (caller) 可以直接沿用傳統 TCP 或 UDP 的呼叫，進入 onvmNet 函式之後才會透過此 ipid.yaml 檔案映射到相對應的 Service ID。

在方法 (method) 的設計上，因為我們需要繼承 \lstinline[language=Go]{net.Conn} 這個 interface，因此我們實作了此 interface 所有提供之 method，讓使用者得以直接呼叫。

另外在設計封包收取 (ReceiveFrom) 時，需要判斷此封包屬於那一個連線 (connection) 的，因此我們設計了 \lstinline{channelMap}，每個連線在聽到 (listen) 連線時會開出一個對應的 channel 並放入 channelMap，當處理者 (handler) 收到 OpenNetVM 給予的封包後，透過 HashMap 的方式以 O(1) 的速度搜尋出相對應的 channel，再將封包送入 channel 得以送到正確的連線中。

設計完 onvmNet 函式庫後，之需將 free5GC 內部 PFCP 函式庫內有呼叫到 \lstinline[language=Go]{net.UDPConn} 的部分改成呼叫 \lstinline[language=Go]{onvmNet.ONVMConn}。另外由於 free5GC 是透過 go module 來維護套件，因此還需跟新 go.mod 之內容。而若有其他 Golang 專案想要嘗試使用 OpenNetVM 平臺，僅需作相同的取代，即可快速移植。
